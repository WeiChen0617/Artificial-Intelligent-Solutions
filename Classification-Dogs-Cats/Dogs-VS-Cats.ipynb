{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS5062_Assessment1_T2_WEI_CHEN_52095454.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6OoRti_Hq5s"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content\"\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7wcmM7uBZpA"
      },
      "source": [
        "\n",
        "!pip install -U -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!echo '{\"username\":\"william0617\",\"key\":\"962aebdb8311ec97100f66aae69b3464\"}' > ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        " \n",
        "!kaggle competitions download -c dogs-vs-cats\n",
        "!unzip \\*.zip\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baMjzEIVRxAp"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "train_filenames = os.listdir('train')\n",
        "train_cat = filter(lambda x: x[:3] == 'cat', train_filenames)\n",
        "train_dog = filter(lambda x: x[:3] == 'dog', train_filenames)\n",
        "# Empty saved folders\n",
        "def rmrf_mkdir(dirname):\n",
        "    if os.path.exists(dirname):\n",
        "        shutil.rmtree(dirname)\n",
        "    os.mkdir(dirname)\n",
        "# Create directories and folders\n",
        "rmrf_mkdir('train2')\n",
        "os.mkdir('train2/cat')\n",
        "os.mkdir('train2/dog')\n",
        "rmrf_mkdir('test2')\n",
        "os.symlink('../test1/', 'test2/test')\n",
        "for filename in train_cat:\n",
        "    os.symlink('../../train/' + filename, 'train2/cat/' + filename)\n",
        "for filename in train_dog:\n",
        "    os.symlink('../../train/' + filename, 'train2/dog/' + filename)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRvDzNGentGT"
      },
      "source": [
        "\n",
        "import h5py\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.applications import *\n",
        "from keras.preprocessing.image import *\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEezTPHeDS4S"
      },
      "source": [
        "\n",
        "\n",
        "# export the eigenvector\n",
        "def write_gap(MODEL, image_size, lambda_func=None):\n",
        "    width = image_size[0]\n",
        "    height = image_size[1]\n",
        "    input_tensor = Input((height, width, 3))\n",
        "    x = input_tensor\n",
        "    if lambda_func:\n",
        "        x = Lambda(lambda_func)(x)\n",
        "    base_model = MODEL(input_tensor=x, weights='imagenet', include_top=False)\n",
        "    model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
        "    gen = ImageDataGenerator()\n",
        "    train_generator = gen.flow_from_directory(\"train2\", image_size, shuffle=False, batch_size=16)\n",
        "    test_generator = gen.flow_from_directory(\"test2\", image_size, shuffle=False, batch_size=16, class_mode=None)\n",
        "    train_generator.samples\n",
        "    train = model.predict_generator(train_generator, train_generator.samples)\n",
        "    test = model.predict_generator(test_generator, test_generator.samples)\n",
        "    with h5py.File(\"gap_%s.h5\" % MODEL.__name__) as h:\n",
        "        h.create_dataset(\"train\", data=train)\n",
        "        h.create_dataset(\"test\", data=test)\n",
        "        h.create_dataset(\"label\", data=train_generator.classes)\n",
        "\n",
        "# Performs the export of eigenvector\n",
        "write_gap(ResNet50, (224, 224))\n",
        "# write_gap(InceptionV3, (299, 299), inception_v3.preprocess_input)\n",
        "# write_gap(Xception, (299, 299), xception.preprocess_input)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S9FcvwV2foE"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# load the eigenvector\n",
        "np.random.seed(2017)\n",
        "X_train = []\n",
        "X_test = []\n",
        "for filename in [\"gap_ResNet50.h5\", \"gap_Xception.h5\", \"gap_InceptionV3.h5\"]:\n",
        "    with h5py.File(filename, 'r') as h:\n",
        "        X_train.append(np.array(h['train']))\n",
        "        X_test.append(np.array(h['test']))\n",
        "        y_train = np.array(h['label'])\n",
        "        print( h['label'][:100])\n",
        "\n",
        "X_train = np.concatenate(X_train, axis=1)\n",
        "X_test = np.concatenate(X_test, axis=1)\n",
        "X_train, y_train = shuffle(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj0sSQd03qI1"
      },
      "source": [
        "from tensorflow.python.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "# EarlyStopping\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Reduce Learning Rate\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.1,\n",
        "    patience=3,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6hpzLmlQS-0"
      },
      "source": [
        "# Build the model\n",
        "p_batch_size = 128\n",
        "p_epochs = 1000\n",
        "np.random.seed(2017)\n",
        "input_tensor = Input(X_train.shape[1:])\n",
        "x = Dropout(0.5)(input_tensor)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(input_tensor, x)\n",
        "model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, batch_size=p_batch_size, epochs=p_epochs, validation_split=0.2,\n",
        "                    callbacks=[early_stopping, reduce_lr])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybxOClw3w7Oy"
      },
      "source": [
        "history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH-cOT8X6FT3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "print(history.history.keys())\n",
        "# Data Visualization\n",
        "# Show training results\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "test_loss, test_acc = model.evaluate(X_train, y_train, batch_size=p_batch_size, steps=10)\n",
        "print('val_loss: {:.3f}\\nval_acc: {:.3f}'.format(test_loss, test_acc))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXDx9GC9Kysz"
      },
      "source": [
        "y_pred = model.predict(X_test, verbose=1)\n",
        "# y_pred = y_pred.clip(min=0.005, max=0.995)\n",
        "test_loss, test_acc = model.evaluate(X_test, y_pred, batch_size=p_batch_size, steps=10)\n",
        "print('val_loss: {:.3f}\\nval_acc: {:.3f}'.format(test_loss, test_acc))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RCID7E764Dk"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import *\n",
        "\n",
        "df=pd.read_csv('sampleSubmission.csv')\n",
        "\n",
        "\n",
        "gen = ImageDataGenerator()\n",
        "test_generator = gen.flow_from_directory(\"test2\", (224, 224), shuffle=False, \n",
        "                                         batch_size=16, class_mode=None)\n",
        "\n",
        "for i, fname in enumerate(test_generator.filenames):\n",
        "    index = int(fname[fname.rfind('/')+1:fname.rfind('.')])\n",
        "    df.loc[i,'label']=y_pred[i]\n",
        "\n",
        "df.to_csv('pred.csv', index=None)\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--4QJymJshjU"
      },
      "source": [
        "y_pred.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wALOm5VEsnQx"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}